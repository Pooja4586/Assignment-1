{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54345786",
   "metadata": {},
   "source": [
    " Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-1\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "# scraping a wikipedia article to list all tags\n",
    "url_link = 'https://en.wikipedia.org/wiki/Main_Page' \n",
    "request = requests.get(url_link)\n",
    " \n",
    "soup = BeautifulSoup(request.text, 'html5lib') #Parsing\n",
    " \n",
    "# creating a list of all common heading tags for matching \n",
    "\n",
    "head_tags = [\"h1\", \"h2\", \"h3\" ,\"h4\", \"h5\" , \"h6\"]\n",
    "\n",
    "for tags in soup.find_all(head_tags):\n",
    "    print(tags.name + ' : ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02698f",
   "metadata": {},
   "source": [
    " Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08035187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-2\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# scraping Imdb Website for top 100 movies\n",
    "\n",
    "url_link = 'https://www.imdb.com/chart/top/'\n",
    "\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating Empty lists for storing data\n",
    "\n",
    "namelist1=[]\n",
    "namelist2=[]\n",
    "realeselist3=[]\n",
    "list4=[]\n",
    "ratinglist5=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "for title in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    namelist1.append(title.text)\n",
    "\n",
    "for ratings in soup.find_all('td',class_=\"imdbRating\"):\n",
    "    list4.append(ratings.text)\n",
    "\n",
    "\n",
    "for i in range(0,100):\n",
    "\n",
    "    fname=namelist1[i].split()                      #Processing Movie Name and removing extra data\n",
    "    newfname=fname[1:len(fname)-1]\n",
    "    final_name=(\" \".join(newfname))\n",
    "    namelist2.append(final_name)\n",
    "    \n",
    "    realese_year=re.sub(r\"[\\([{})\\]]\", \"\",fname[len(fname)-1])\n",
    "    realeselist3.append(realese_year)                            #Fetching Realese Year from split data and reving brackets\n",
    "    \n",
    "    rating = list4[i].strip()\n",
    "    ratinglist5.append(rating)                       #Dropping extra data associated with rating\n",
    "\n",
    "#Creating Data Frame as asked for displaying data in readable format\n",
    "\n",
    "df = pd.DataFrame({\"Movie Name \": namelist2,\"Year Of Realese \": realeselist3 , \"Imdb Rating\" : ratinglist5})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7cfee",
   "metadata": {},
   "source": [
    "Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-3\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# scraping Imdb Website for top 100 indian movies\n",
    "\n",
    "url_link = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating Empty lists for storing data\n",
    "\n",
    "namelist1=[]\n",
    "namelist2=[]\n",
    "realeselist3=[]\n",
    "list4=[]\n",
    "ratinglist5=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "for title in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    namelist1.append(title.text)\n",
    "\n",
    "for ratings in soup.find_all('td',class_=\"imdbRating\"):\n",
    "    list4.append(ratings.text)\n",
    "\n",
    "\n",
    "for i in range(0,100):\n",
    "\n",
    "    fname=namelist1[i].split()                      #Processing Movie Name and removing extra data\n",
    "    newfname=fname[1:len(fname)-1]\n",
    "    final_name=(\" \".join(newfname))\n",
    "    namelist2.append(final_name)\n",
    "    \n",
    "    realese_year=re.sub(r\"[\\([{})\\]]\", \"\",fname[len(fname)-1])\n",
    "    realeselist3.append(realese_year)                            #Fetching Realese Year from split data and reving brackets\n",
    "    \n",
    "    rating = list4[i].strip()\n",
    "    ratinglist5.append(rating)                       #Dropping extra data associated with rating\n",
    "\n",
    "#Creating Data Frame as asked for displaying data in readable format\n",
    "\n",
    "df = pd.DataFrame({\"Movie Name \": namelist2,\"Year Of Realese \": realeselist3 , \"Imdb Rating\" : ratinglist5})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4360e",
   "metadata": {},
   "source": [
    "Write a python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae537243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-4\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#scraping a site for fetching list of former presidents and Term of Office\n",
    "\n",
    "url_link = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating Empty Lists for working\n",
    "\n",
    "list1=[]\n",
    "namelist=[]\n",
    "termlist=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')   #Parsing of Data\n",
    " \n",
    "#Fetching Required data from relevent tags and class\n",
    "\n",
    "for index in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    list1.append(index.text)\n",
    "\n",
    "#Seperating Name and Term , Removing extra data \n",
    "\n",
    "for i in range(0,len(list1)):\n",
    "    name = list1[i].split(\"\\n\")[1]\n",
    "    term=  list1[i].split(\"\\n\")[2]\n",
    "    \n",
    "    namelist.append(name.split(\"(\")[0])       #Removing Birth information\n",
    "    termlist.append(term.split(\": \")[1])      #Removing Extra text before Term of service\n",
    "\n",
    "#printing required data using Data Frame\n",
    "\n",
    "df=pd.DataFrame({\"President Name\": namelist,\"Term of Office\": termlist}) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feadfb1f",
   "metadata": {},
   "source": [
    "Write a python program to scrape cricket rankings from icc-cricket.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2078046",
   "metadata": {},
   "source": [
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-5(a)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping The Icc website for ODI team Ranking(mens)\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating Empty Lists\n",
    "\n",
    "rating_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')               #Parsing\n",
    "\n",
    "#Finding Ratings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Points\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    points_list.append(index.text)\n",
    "\n",
    "#Finding Team name\n",
    "\n",
    "for index in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    name_list.append(index.text)   \n",
    "    \n",
    "#Finding Data of First team and appending at first position\n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    matches1=index.text \n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    points1=index.text\n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Seperating Points and matches\n",
    "\n",
    "for i in range(0,len(points_list)):\n",
    "    if(i%2==0):\n",
    "        list4.append(points_list[i])\n",
    "    else:\n",
    "        list5.append(points_list[i])\n",
    "\n",
    "list4.insert(0,matches1)\n",
    "list5.insert(0,points1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Points\": list5[0:10] , \"Matches\" : list4[0:10] ,\"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a618bb84",
   "metadata": {},
   "source": [
    "5(b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fe3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-5(b)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping ICC website for batsman ranking\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#creating Empty Lists\n",
    "\n",
    "player_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Finding Ratings\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Names\n",
    "\n",
    "for index in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    name_list.append(index.text)\n",
    "\n",
    "#Finding Rankings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_list.append(index.text)\n",
    "\n",
    "#Finding Details of top player and appending\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    name1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    country1=index.text.strip()\n",
    "for i in range(0,len(player_list)):\n",
    "    name=(player_list[i].strip())\n",
    "    list4.append(name)\n",
    "    \n",
    "name_list.insert(0,country1)\n",
    "list4.insert(0,name1)\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Player Name\": list4[0:10] , \"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eff4a7",
   "metadata": {},
   "source": [
    "5(c) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a46a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-5(c)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping ICC website for bowler ranking\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#creating Empty Lists\n",
    "\n",
    "player_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Finding Ratings\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Names\n",
    "\n",
    "for index in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    name_list.append(index.text)\n",
    "\n",
    "#Finding Rankings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_list.append(index.text)\n",
    "\n",
    "#Finding Details of top player and appending\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    name1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    country1=index.text.strip()\n",
    "for i in range(0,len(player_list)):\n",
    "    name=(player_list[i].strip())\n",
    "    list4.append(name)\n",
    "    \n",
    "name_list.insert(0,country1)\n",
    "list4.insert(0,name1)\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Player Name\": list4[0:10] , \"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ecef3",
   "metadata": {},
   "source": [
    "Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51777182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-6(a)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping The Icc website for ODI team Ranking(women)\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating Empty Lists\n",
    "\n",
    "rating_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')               #Parsing\n",
    "\n",
    "#Finding Ratings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Points\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    points_list.append(index.text)\n",
    "\n",
    "#Finding Team name\n",
    "\n",
    "for index in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    name_list.append(index.text)   \n",
    "    \n",
    "#Finding Data of First team and appending at first position\n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    matches1=index.text \n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    points1=index.text\n",
    "\n",
    "for index in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Seperating Points and matches\n",
    "\n",
    "for i in range(0,len(points_list)):\n",
    "    if(i%2==0):\n",
    "        list4.append(points_list[i])\n",
    "    else:\n",
    "        list5.append(points_list[i])\n",
    "\n",
    "list4.insert(0,matches1)\n",
    "list5.insert(0,points1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Points\": list5[0:10] , \"Matches\" : list4[0:10] ,\"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070dd363",
   "metadata": {},
   "source": [
    "6(b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc451342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-6(b)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping ICC website for batting ranking\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#creating Empty Lists\n",
    "\n",
    "player_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Finding Ratings\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Names\n",
    "\n",
    "for index in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    name_list.append(index.text)\n",
    "\n",
    "#Finding Rankings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_list.append(index.text)\n",
    "\n",
    "#Finding Details of top player and appending\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    name1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    country1=index.text.strip()\n",
    "for i in range(0,len(player_list)):\n",
    "    name=(player_list[i].strip())\n",
    "    list4.append(name)\n",
    "    \n",
    "name_list.insert(0,country1)\n",
    "list4.insert(0,name1)\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Player Name\": list4[0:10] , \"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162de8c",
   "metadata": {},
   "source": [
    "6(c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d527e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-6(c)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping ICC website for allrounder ranking\n",
    "\n",
    "url_link = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#creating Empty Lists\n",
    "\n",
    "player_list=[]\n",
    "points_list=[]\n",
    "name_list=[]\n",
    "list4=[]\n",
    "list5=[]\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Finding Ratings\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating_list.append(index.text)\n",
    "\n",
    "#Finding Names\n",
    "\n",
    "for index in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    name_list.append(index.text)\n",
    "\n",
    "#Finding Rankings\n",
    "\n",
    "for index in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_list.append(index.text)\n",
    "\n",
    "#Finding Details of top player and appending\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    ranking1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    name1=index.text.strip()\n",
    "\n",
    "for index in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    country1=index.text.strip()\n",
    "for i in range(0,len(player_list)):\n",
    "    name=(player_list[i].strip())\n",
    "    list4.append(name)\n",
    "    \n",
    "name_list.insert(0,country1)\n",
    "list4.insert(0,name1)\n",
    "rating_list.insert(0,ranking1)\n",
    "\n",
    "#Printing top 10 names using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Team Name \": name_list[0:10],\"Player Name\": list4[0:10] , \"Ranking\":rating_list[0:10]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50666298",
   "metadata": {},
   "source": [
    "Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-7\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping a News Portal\n",
    "\n",
    "url_link = 'https://www.cnbc.com/world/?region=world'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating List for storing Data\n",
    "\n",
    "time_list=[]\n",
    "headline=[]\n",
    "newslink=[]\n",
    "\n",
    "#Parsing\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Getting Time Details\n",
    "\n",
    "for index in soup.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    time_list.append(index.text)\n",
    "\n",
    "#Getting Headlines\n",
    "\n",
    "for index in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(index.text)\n",
    "\n",
    "#Getting Link of News\n",
    "\n",
    "for index in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    newslink.append(index.get(\"href\"))\n",
    "\n",
    "#Printing Data using Data Frame\n",
    "\n",
    "df = pd.DataFrame({\"Headline \": headline,\"Time\":time_list, \"News Link Link\" : newslink })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6ac3c",
   "metadata": {},
   "source": [
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title \n",
    "ii) Authors\n",
    "iii) Published Date \n",
    "iv) Paper URL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-8\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "# scraping a site for fetching most downloaded articles\n",
    "\n",
    "url_link = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "request = requests.get(url_link)\n",
    " \n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Creating Empty Lists\n",
    "\n",
    "author_list=[]\n",
    "article_list=[]\n",
    "date_list=[]\n",
    "url_list=[]\n",
    "\n",
    "#Fetching Author\n",
    "\n",
    "for index in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    author_list.append(index.text)\n",
    "\n",
    "#Fetching Article\n",
    "\n",
    "for index in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    article_list.append(index.text)\n",
    "\n",
    "#Fetching Date of upload\n",
    "\n",
    "for index in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date_list.append(index.text)\n",
    "\n",
    "#Fetching URL's of Articles\n",
    "\n",
    "for link in soup.find_all('a', class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    url_list.append(link.get('href'))  \n",
    "\n",
    "df = pd.DataFrame({\"Article Name \": article_list,\"Date Uploaded\": date_list , \"Authors\":author_list ,\"URL of Artile\" : url_list})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d67b9b",
   "metadata": {},
   "source": [
    "Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location \n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-9\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping a restaurent website for various details \n",
    "\n",
    "url_link = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "request = requests.get(url_link)\n",
    "\n",
    "#Creating empty lists\n",
    "\n",
    "name_list=[]\n",
    "rating=[]\n",
    "location=[]\n",
    "cuisine=[]\n",
    "web_list=[]\n",
    "\n",
    "#parsing\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Getting Restaurent names\n",
    "\n",
    "for index in soup.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    name_list.append(index.text)\n",
    "\n",
    "#Getting Restaurent location\n",
    "\n",
    "for index in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(index.text)\n",
    "\n",
    "#Getting Restaurent cuisines\n",
    "\n",
    "for index in soup.find_all('div',class_=\"detail-info\"):\n",
    "    cuisine.append(index.text.split('|')[1])\n",
    "\n",
    "#rating on site    \n",
    "\n",
    "for index in soup.find_all('div',class_=\"restnt-rating rating-4 hide\"):\n",
    "    rating.append(index.text)   \n",
    "\n",
    "#Getting image URL\n",
    "\n",
    "for index in soup.find_all('img', class_=\"no-img\"):\n",
    "    web_list.append(index.get(\"data-src\"))   \n",
    "\n",
    "\n",
    "#Displaying data using data frames\n",
    "\n",
    "df = pd.DataFrame({\"Restaurant Name \": name_list,\"Cuisine\":cuisine, \"Location\": location ,\"Rating\":rating,\"Image Link\" : web_list })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd721c",
   "metadata": {},
   "source": [
    "10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank \n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup Assignment-1 Question-10\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# scraping a website for finding top publications\n",
    "\n",
    "url_link = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "request = requests.get(url_link)\n",
    "ranking_list=[]\n",
    "publication_list=[]\n",
    "h5_list=[]\n",
    "h5_index=[]\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'html5lib')\n",
    "\n",
    "#Finding Ranking\n",
    "\n",
    "for index in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    ranking_list.append(index.text.replace(\".\",\" \"))\n",
    "\n",
    "#Finding Publication\n",
    "\n",
    "for index in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication_list.append(index.text)\n",
    "\n",
    "#Finding H5 list\n",
    "    \n",
    "for index in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_list.append(index.text)\n",
    "\n",
    "#Finding H5 index\n",
    "\n",
    "for index in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_index.append(index.text)   \n",
    "\n",
    "#Printing required data\n",
    "\n",
    "df = pd.DataFrame({\"Ranking \": ranking_list,\"Publication List\": publication_list ,\"H5-Index\":h5_index, \"H5-Median\":h5_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4efc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
